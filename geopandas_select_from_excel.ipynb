{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYS92wwR9DxGNbOE2G6Awj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Subset a Shapefile using a Spreadsheet\n",
        "\n",
        "## Overview\n",
        "\n",
        "This tutorial shows you how to use extract a subset from a shapefile using data contained in an Excel spreadsheet.\n",
        "\n",
        "We will be working with a parcels data layer for the city of San Francisco, California. Given a list of parcel ids in a spreadsheet, we will extract those parcels and save it to another data layer.\n",
        "\n",
        "Input Layers:\n",
        "* `sf_parcels.zip`: A shapefile of parcels San Francisco\n",
        "* `parcels_to_export.xlsx`: A spreadsheet containing list of parcels to export.\n",
        "\n",
        "Output:\n",
        "* `subset.shp.zip`: A zipped shapefile containing a subset of parcels based on the spreadsheet.\n",
        "\n",
        "Data Credit: Parcels downloaded from [DataSF Open Data Portal](https://datasf.org/opendata/)\n",
        "\n",
        "---\n",
        "A video walkthrough of the tutorial is available below\n",
        "\n",
        "[![Watch Video Tutorial](https://img.youtube.com/vi/knrzzq0rsiM/0.jpg)](https://www.youtube.com/watch?v=knrzzq0rsiM)\n",
        "\n"
      ],
      "metadata": {
        "id": "N6CsIukeW1-7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JepwzAj2U5L5"
      },
      "source": [
        "## Setup and Data Download\n",
        "\n",
        "The following blocks of code will install the required packages and download the datasets to your Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv5B0Pq-U5L5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "try:\n",
        "    import geopandas\n",
        "except ModuleNotFoundError:\n",
        "    if 'google.colab' in str(get_ipython()):\n",
        "        !apt install libspatialindex-dev -qq\n",
        "        !pip install fiona shapely pyproj rtree --quiet\n",
        "        !pip install geopandas --quiet\n",
        "    else:\n",
        "        print('geopandas not found, please install via conda in your environment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQovPAjjU5L6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Zndcd8KU5L6"
      },
      "outputs": [],
      "source": [
        "data_folder = 'data'\n",
        "output_folder = 'output'\n",
        "\n",
        "if not os.path.exists(data_folder):\n",
        "    os.mkdir(data_folder)\n",
        "if not os.path.exists(output_folder):\n",
        "    os.mkdir(output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9cAjPXSU5L6"
      },
      "outputs": [],
      "source": [
        "def download(url):\n",
        "    filename = os.path.join(data_folder, os.path.basename(url))\n",
        "    if not os.path.exists(filename):\n",
        "        from urllib.request import urlretrieve\n",
        "        local, _ = urlretrieve(url, filename)\n",
        "        print('Downloaded ' + local)\n",
        "    \n",
        "download('https://github.com/spatialthoughts/python-tutorials/raw/main/data/' +\n",
        "         'sf_parcels.zip')\n",
        "download('https://github.com/spatialthoughts/python-tutorials/raw/main/data/' +\n",
        "         'parcels_to_export.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Procedure"
      ],
      "metadata": {
        "id": "-D-U34cbYkrC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first unzip the `sf_parcels.zip` archive and extract the shapefile contained inside. Then we can read it using GeoPandas.\n",
        "\n",
        "> GeoPandas can read zipped files directly using the `zip://` prefix as described in [Reading and Writing Files](https://geopandas.org/en/stable/docs/user_guide/io.html) section of the documentation. `gpd.read_file('zip:///data/sf_parcels.zip')`. But it was much slower than unzipping and reading the shapefile."
      ],
      "metadata": {
        "id": "gE90KEg9Z9BU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parcels_filepath = os.path.join(data_folder, 'sf_parcels.zip')"
      ],
      "metadata": {
        "id": "QWwnTyVyoFMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use Python's built-in `zipfile` module to extract the files in the data directory."
      ],
      "metadata": {
        "id": "NWqvtTRPb27L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(parcels_filepath) as zf:\n",
        "  zf.extractall(data_folder)"
      ],
      "metadata": {
        "id": "zIxrmIW0Y9By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once unzipped, we can read the parcels shapefile using GeoPandas."
      ],
      "metadata": {
        "id": "XoHkIBvzb-6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parcels_shp = os.path.join(data_folder, 'sf_parcels.shp')\n",
        "parcels_gdf = gpd.read_file(parcels_shp)"
      ],
      "metadata": {
        "id": "0kv8x2JCoMFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preview the resulting GeoDataFrame. The parcel ids are contained in the `mapblklot` column."
      ],
      "metadata": {
        "id": "X-la_03PcLth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parcels_gdf"
      ],
      "metadata": {
        "id": "Kz-zLg_ucLAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we read the Excel file containing the parcel ids that we need to export."
      ],
      "metadata": {
        "id": "IIszH40icQ_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "export_file_path = os.path.join(data_folder, 'parcels_to_export.xlsx')"
      ],
      "metadata": {
        "id": "OwYzuk3QoQxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas can read Excel files directly using `read_excel()` function. If you get an error, make sure to install the package `openpyxl` which is used to read excel files."
      ],
      "metadata": {
        "id": "X4kJD_XOciij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "export_df = pd.read_excel(export_file_path)\n",
        "export_df"
      ],
      "metadata": {
        "id": "Pc2UHj9VprO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to export all parcels whose ids are given in the `mapblklot` column. We extract that column and create a list."
      ],
      "metadata": {
        "id": "5dRTB-ONctAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_list = export_df['blklot'].values\n",
        "id_list"
      ],
      "metadata": {
        "id": "7jPpLxJvpxw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can use Pandas `isin()` method to filter the GeoDataFrame where the `\n",
        "blklot` column matches any ids from the `id_list`."
      ],
      "metadata": {
        "id": "2sFfj8Y4dCGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset_gdf = parcels_gdf[parcels_gdf['blklot'].isin(id_list)]\n",
        "subset_gdf"
      ],
      "metadata": {
        "id": "mjJ_I_AsqE4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have successfully selected the subset of parcels. We are ready to save the resulting GeoDataFrame as a shapefile. We define the output file path and save the `subset_gdf`."
      ],
      "metadata": {
        "id": "rFuW7npBdWBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_file = 'subset.shp'\n",
        "output_path = os.path.join(output_folder, output_file)"
      ],
      "metadata": {
        "id": "2adR9beyqSbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subset_gdf.to_file(output_path)"
      ],
      "metadata": {
        "id": "kyHcRUOfqmgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For ease of data sharing, let's zip all the shapefile parts into a single archive. We again use the `zipfile` module and use the `write()` method to add each sidecar file for the shapefile. The `arcname` parameter is used to avoid creating a sub-folder inside the archive."
      ],
      "metadata": {
        "id": "TWr7mRiQdvAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_zip = 'subset.zip'\n",
        "output_zip_path = os.path.join(output_folder, output_zip)\n",
        "\n",
        "with zipfile.ZipFile(output_zip_path, 'w') as output_zf:\n",
        "  for ext in ['.shp', '.shx', '.prj', '.dbf']:\n",
        "    filename = 'subset' + ext\n",
        "    filepath = os.path.join(output_folder, filename)\n",
        "    output_zf.write(filepath, arcname=filename)"
      ],
      "metadata": {
        "id": "AhD3TXNfqop0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}